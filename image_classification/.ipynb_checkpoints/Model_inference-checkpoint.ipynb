{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain a prediction of the class we :\n",
    "1. we will create **several** versions of the test image using an augmentation policy\n",
    "2. will use the models training-resolution as a **sliding window** to obtain a scan of the probability over multiple patches in the test image variants\n",
    "3. **aggregate** the probabilities to get a final score\n",
    "4. **reduce** the probabilities to yes / no melanoma.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import pydicom\n",
    "import skimage\n",
    "import albumentations\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.utils import *\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import get_image_backend\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "import natsort\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import models as tv_models\n",
    "torchvision_models = dir(tv_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use patient information: if a patient has one image with melanoma it is unlikely that the others are melanoma as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root = '/home/bramiozo/DATA/ISIC2020'\n",
    "root = '/media/bramiozo/DATA-FAST/kaggle/image_classification/MEDICAL/melanoma'\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_patient_mapping = pd.read_csv(\"TRAINING_1024/ISIC_2020_test.csv\")\n",
    "img_pat = load_patient_mapping[['image_name', 'patient_id']].set_index('image_name').to_dict()['patient_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 1\n",
    "use_cpu = False\n",
    "use_amp = False\n",
    "begin_resize = False\n",
    "stride = 280\n",
    "map_sel = 2 \n",
    "num_classes=2\n",
    "test_count = 10982 # number of test samples\n",
    "smart_mean = True\n",
    "get_all_probas = False # USE TO EXTRACT MORE LABELS\n",
    "submit_to_kaggle = False\n",
    "debug = False\n",
    "\n",
    "run_settings = defaultdict(dict)\n",
    "run_settings['resize'] = {'resize': (300, 300), 'scan_res': 290, 'randomcrop': None, 'centercrop': None, \n",
    "                          'stride': 280, 'TTA': 7, 'proba_aggregation': 'mean_softmax',\n",
    "                          'use_inference_weights': False}\n",
    "run_settings['centercrop'] = {'resize': None, 'scan_res': 150, 'randomcrop': (500,300), 'centercrop': None,\n",
    "                              'stride': 140, 'TTA': 7, 'proba_aggregation': 'logmean',\n",
    "                              'use_inference_weights': False}\n",
    "\n",
    "# proba_aggregation: mean_softmax, softmax_mean_linear, logmean\n",
    "\n",
    "modelloc_dict = defaultdict(dict)\n",
    "\n",
    "#modelloc_dict['xception']['resize'] = '../_models/melanoma/xception_DepthALL_40epochs_lastALLlayers_resized_balancingWsampler_batchsize32_optimizerAdaTuneAdam_numClass2_weightedLoss_wAugmentation_res400x400_dat_numGPU1_cross_entropy.pyth'\n",
    "\n",
    "modelloc_dict['efficient_net_b0']['resize'] = '../_models/melanoma/good/tf_efficientnet_b0_ns_DepthALL_60epochs_lastALLlayers_resized_balancingWsampler_batchsize32_optimizerAdaTuneAdam_numClass2_weightedLoss_wAugmentation_res300x300_datTRAINING_1024_BINOMIAL_numGPU1_cross_entropy_lr1e-4.pyth'\n",
    "#modelloc_dict['efficient_net_b0']['centercrop'] = '../_models/melanoma/tf_efficientnet_b0_ns_DepthALL_20epochs_lastALLlayers_randomcropped_balancingWsampler_batchsize32_optimizerAdaTuneAdam_numClass2_weightedLoss_wAugmentation_res300x300_datTRAINING_1024_BINOMIAL_numGPU1_cross_entropy.pyth'\n",
    "#modelloc_dict['efficient_net_b0']['segmentation'] =\n",
    "\n",
    "modelloc_dict['regnet_064']['resize'] = '../_models/melanoma/good/regnety_064_DepthALL_60epochs_lastALLlayers_resized_balancingWsampler_batchsize32_optimizerAdaTuneAdam_numClass2_weightedLoss_wAugmentation_res300x300_datTRAINING_1024_BINOMIAL_numGPU1_cross_entropy_lr4e-5.pyth'\n",
    "modelloc_dict['regnet_064']['centercrop'] = '../_models/melanoma/good/regnety_064_DepthALL_40epochs_lastALLlayers_randomcropped_balancingWsampler_batchsize32_optimizerAdaTuneAdam_numClass2_weightedLoss_wAugmentation_res300x300_datTRAINING_1024_BINOMIAL_numGPU1_cross_entropy.pyth'\n",
    "#modelloc_dict['regnet_064']['segmentation'] =\n",
    "\n",
    "\n",
    "\n",
    "image_loc = 'TRAINING_1024/TEST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a model dictionary, that is indexed as follows:\n",
    "```\n",
    "model_name: \n",
    "    resize:\n",
    "    centercrop:\n",
    "    segmentation:\n",
    "```\n",
    "\n",
    "For the ```resize``` models we resize the test images, for the ```centercrop``` models we apply a scan on the test images and for the ```segmentation``` models we need to apply the segmentation model on the images before classification. I.e. three different test image treatments, for each model, for each TTA run.\n",
    "\n",
    "If we assume the following imagenet pre-trained models:\n",
    "* 3x efficientnet; say B0, B2, B6\n",
    "* 3x regnet; say 006, 032 and 16\n",
    "* Exception\n",
    "* InceptionV4\n",
    "\n",
    "We end up with ```(2+#-scans) x #-TTA x #-num-models``` inference runs. I.e. with a minimum of 4 scans and a TTA of 3 we have ```18 * #-num-models``` inference runs, or ```30 * #-num-models``` inference runs.\n",
    "One inference run on a RTX2080 takes about **5** minutes, i.e. about **2.5**  hours of inference **PER MODEL**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA: put class_map inside the model..\n",
    "class_maps = {1:{'ak': 0, 'anv': 1, 'bcc': 2, 'bkl': 3, 'df': 4, 'mel': 5, 'nv': 6, 'scc': 7,'vasc': 8},\n",
    "              2:{'non-mel':0, 'mel': 1},\n",
    "              3:{'ak': 0, 'anv': 1, 'bcc':2, 'bkl':3, 'df':4, 'mel':5, 'misc':6, 'nv':7, 'scc':8, 'vasc':9}\n",
    "             }\n",
    "\n",
    "class_weights = {1:{'ak': 70000/1000, 'anv': 70000/500, 'bcc': 70000/4000, 'bkl': 70000/3000, \n",
    "                    'df': 70000/500, 'mel': 70000/6000, 'nv': 70000/20000, 'scc': 70000/1000,\n",
    "                    'vasc': 70000/500},\n",
    "                 2:{'non-mel': 33/6, 'mel': 33/27},\n",
    "                 3:{'ak': 70000/1000, 'anv': 70000/500, 'bcc': 70000/4000, 'bkl': 70000/3000, \n",
    "                    'df': 70000/500, 'mel': 70000/6000, 'nv': 70000/20000, 'scc': 70000/1000,\n",
    "                    'vasc': 70000/500, 'misc': 70000/27000}\n",
    "                }\n",
    "\n",
    "class_map = class_maps[map_sel]\n",
    "class_weight = class_weights[map_sel]\n",
    "ind_class = inds_class = {v:k for k,v in class_map.items()}\n",
    "ind_weights = {class_map[k]:v for k,v in class_weight.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.module = module # that I actually define.\n",
    "    def forward(self, x):\n",
    "        return self.module(x)      \n",
    "    \n",
    "class TestDataSet(Dataset):\n",
    "    # https://discuss.pytorch.org/t/how-does-concatdataset-work/60083\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs) # natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image, img_loc\n",
    "    \n",
    "class Tinterpolate:\n",
    "    def __init__(self, size, random_resize_crop=False):\n",
    "        self.size = size\n",
    "        self.rnd_resize_crop = random_resize_crop\n",
    "    def __call__(self, x):\n",
    "        if self.rnd_resize_crop:\n",
    "            return TF.to_tensor(TF.RandomResizedCrop(TF.to_pil_images(x), size=self.size))\n",
    "        else:\n",
    "            return TF.to_tensor(TF.resize(TF.to_pil_image(x), size=self.size))\n",
    "        \n",
    "\n",
    "# credits: https://www.kaggle.com/c/siim-isic-melanoma-cp=0.5, num_holes=8, max_h_size=8, max_w_size=8lassification/discussion/159476\n",
    "# credits: https://www.kaggle.com/allunia/don-t-turn-into-a-smoothie-after-the-shake-up\n",
    "def random_microscope(img):\n",
    "    circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8), # image placeholder\n",
    "                        (img.shape[0]//2, img.shape[1]//2), # center point of circle\n",
    "                        np.random.randint(img.shape[0]//1.75 - 1, img.shape[0]//1.75 + 15), # radius\n",
    "                        (0, 0, 0), # color\n",
    "                        -1)\n",
    "\n",
    "    mask = circle - 255\n",
    "    img = np.multiply(img, mask)\n",
    "    return img\n",
    "\n",
    "class Microscope:\n",
    "    \"\"\"\n",
    "    Cutting out the edges around the center circle of the image\n",
    "    Imitating a picture, taken through the microscope\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of applying an augmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to apply transformation to.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with transformation.\n",
    "        \"\"\"\n",
    "        img = np.asarray(img)\n",
    "        if np.random.random() <self.p:\n",
    "            img = random_microscope(img)\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        return img\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "\n",
    "class AutoContrast:\n",
    "    def __init__(self, p: float= 0.5, cutoff: float = 0.2):\n",
    "        self.p = p        \n",
    "        self.cutoff = cutoff\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if np.random.random() < self.p:\n",
    "            return ImageOps.autocontrast(img, cutoff=self.cutoff)\n",
    "        else:\n",
    "            return img\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "    \n",
    "class Equalize:\n",
    "    def __init__(self, p: float= 0.5):\n",
    "        self.p = p\n",
    "\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if np.random.random() < self.p:\n",
    "            return ImageOps.equalize(img)\n",
    "        else:\n",
    "            return img\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "    \n",
    "class Sharpness:\n",
    "    def __init__(self, p: float= 0.5, magnitude: int=3):\n",
    "        self.p = p\n",
    "        self.magnitude = magnitude\n",
    "        self.magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if np.random.random() < self.p:\n",
    "            return ImageEnhance.Sharpness(img)\\\n",
    "                                .enhance(np.random.uniform(self.magnitudes[self.magnitude], \n",
    "                                                        self.magnitudes[self.magnitude+1]))\n",
    "        else:\n",
    "            return img\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, p=0.5, ksize=3, sigma=1):\n",
    "        self.p = p\n",
    "        self.ksize = ksize\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if np.random.random()<self.p:  \n",
    "            img = np.array(img)\n",
    "            res = albumentations.augmentations.transforms.F.gaussian_blur(img, self.ksize)\n",
    "            return res \n",
    "        else:\n",
    "            return img        \n",
    "\n",
    "    def __repr__(self):        \n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "# albumentations.augmentations.transforms.Cutout(num_holes=5, \n",
    "#max_h_size=32, max_w_size=32, fill_value=0, always_apply=False, p=0.2)\n",
    "#from albumentations.augmentations.transforms import Cutout as AlbCutout\n",
    "\n",
    "class CutOut():\n",
    "    def __init__(self, p: float=0.5, min_holes: int=2, max_holes: int=6, \n",
    "                 fill_value: int=0, max_height: int=32, max_width: int=32,\n",
    "                 min_height: int=8, min_width: int=8):\n",
    "        self.p = p\n",
    "        self.min_holes = min_holes\n",
    "        self.max_holes = max_holes\n",
    "        self.fill_value = fill_value\n",
    "        self.max_height = max_height\n",
    "        self.max_width = max_width\n",
    "        self.min_height = min_height\n",
    "        self.min_width = min_width\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        if np.random.random()<self.p:\n",
    "            \n",
    "            img = np.array(img)\n",
    "            height, width = img.shape[:2]\n",
    "\n",
    "            holes = []\n",
    "            for _n in range(np.random.randint(self.min_holes, self.max_holes)):\n",
    "                hole_height = np.random.randint(self.min_height, self.max_height)\n",
    "                hole_width = np.random.randint(self.min_width, self.max_width)\n",
    "\n",
    "                y1 = np.random.randint(0, height - hole_height)\n",
    "                x1 = np.random.randint(0, width - hole_width)\n",
    "                y2 = y1 + hole_height\n",
    "                x2 = x1 + hole_width\n",
    "                holes.append((x1, y1, x2, y2))\n",
    "            \n",
    "            res = albumentations.augmentations.transforms.F.cutout(img, holes, self.fill_value)\n",
    "            return res # return Image.fromarray(res)\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "    \n",
    "class Hair:\n",
    "    \"\"\"\n",
    "    Impose an image of a hair to the target image\n",
    "\n",
    "    Args:\n",
    "        hairs (int): maximum number of hairs to impose\n",
    "        hairs_folder (str): path to the folder with hairs images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hairs: int = 1, p: float = 0.1, scale: float = 0.1, hairs_folder: str = \"\"):\n",
    "        self.p = p\n",
    "        self.scale=0.10\n",
    "        self.hairs = hairs\n",
    "        self.hairs_folder = hairs_folder\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to draw hairs on.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with drawn hairs.\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.random.random()< self.p:\n",
    "            \n",
    "            '''\n",
    "            scale_percent = self.scale*100 # percent of original size\n",
    "            width = int(img.shape[1] * scale_percent / 100)\n",
    "            height = int(img.shape[0] * scale_percent / 100)\n",
    "            dim = (width, height)\n",
    "            # resize image\n",
    "            img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)            \n",
    "            '''\n",
    "            n_hairs = np.random.randint(1, self.hairs)\n",
    "\n",
    "            if not n_hairs:\n",
    "                return img                \n",
    "            \n",
    "            \n",
    "            #img = TF.resize(img, size=250)\n",
    "            img = np.array(img)\n",
    "            \n",
    "            height, width, _ = img.shape  # target image width and height\n",
    "            hair_images = [im for im in os.listdir(self.hairs_folder) if 'png' in im]\n",
    "\n",
    "            for _ in range(n_hairs):\n",
    "                hair = cv2.imread(os.path.join(self.hairs_folder, np.random.choice(hair_images)))\n",
    "                hair = cv2.flip(hair, np.random.choice([-1, 0, 1]))\n",
    "                hair = cv2.rotate(hair, np.random.choice([0, 1, 2]))\n",
    "                hair = cv2.resize(hair, (width-50, height-50))\n",
    "                \n",
    "\n",
    "                h_height, h_width, _ = hair.shape  # hair image width and height\n",
    "                print(img.shape, hair.shape)\n",
    "                roi_ho = np.random.randint(0, img.shape[0] - hair.shape[0])\n",
    "                roi_wo = np.random.randint(0, img.shape[1] - hair.shape[1])\n",
    "                roi = img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
    "\n",
    "                # Creating a mask and inverse mask\n",
    "                img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
    "                ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "                mask_inv = cv2.bitwise_not(mask)\n",
    "                # Now black-out the area of hair in ROI\n",
    "                img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "                # Take only region of hair from hair image.\n",
    "                hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
    "                # Put hair in ROI and modify the target image\n",
    "                dst = cv2.add(img_bg, hair_fg)\n",
    "\n",
    "                #img.setflags(write=1)\n",
    "                img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
    "                \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n",
    "            return img\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(hairs={self.hairs}, hairs_folder=\"{self.hairs_folder}\")'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU's Detected\n"
     ]
    }
   ],
   "source": [
    "gpu_str = \",\".join([str(i) for i in range(num_gpu)])\n",
    "gpu_str = \"\" if use_cpu else gpu_str\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_str\n",
    "GPU_COUNT = torch.cuda.device_count() \n",
    "\n",
    "if GPU_COUNT>1:\n",
    "    device = torch.device(\"cuda\" if (torch.cuda.is_available()) and (use_cpu==False) else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) and (use_cpu==False) else \"cpu\")\n",
    "    \n",
    "if num_gpu>GPU_COUNT:\n",
    "    raise Exception(\"We see only {} instead of {} GPU's\".format(GPU_COUNT, num_gpu))\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    print(\"{} GPU's Detected\".format(GPU_COUNT))\n",
    "else:\n",
    "    print(\"GPU is NOT detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision_models = ['shufflenetv2', 'wide_resnet50_2', 'wide_resnet101_2', 'squeezenet1_1', \n",
    "                      'resnext50_32x4d', 'resnext101_32x8d', 'shufflenet_v2_x2_0',\n",
    "                      'mnasnet1_3']\n",
    "\n",
    "pretrainedmodels_models = ['inceptionv4', 'resnet152', 'nasnetamobile', 'xception']\n",
    "\n",
    "efficientnet_models = ['efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', \n",
    "                       'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5',\n",
    "                       'efficientnet-b6', 'efficientnet-b7', 'efficientnet-b8']\n",
    "\n",
    "timm_models = ['tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'mixnet_xl', 'gluon_xception65', 'xception',\n",
    "               'tf_efficientnet_b7_ns', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b5_ns', \n",
    "               'tf_efficientnet_b4_ns', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b2_ns',\n",
    "               'tf_efficientnet_b1_ns', 'tf_efficientnet_b0_ns',\n",
    "               'tf_efficientnet_l2_ns_475',\n",
    "               'seresnext101_32x4d', 'resnext101_64x4d', 'regnety_002', 'regnety_004',\n",
    "               'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040',\n",
    "               'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320',\n",
    "               'tf_mobilenetv3_large_100', 'efficientnet_b1_pruned', 'efficientnet_b2_pruned',\n",
    "               'efficientnet_b3_pruned', 'densenet264d_iabn', 'mobilenetv2_120d',\n",
    "               'mobilenetv3_large_100', 'mixnet_m', 'mixnet_l']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_model(model_name):\n",
    "    print(model_name)\n",
    "    if model_name in torchvision_models:\n",
    "        print(\"Pulling model from torchvision model zoo\")\n",
    "        return eval('tv_models.'+model_name+'()')\n",
    "    elif model_name.lower() in efficientnet_models:    \n",
    "        print(\"Pulling model from efficientnet model zoo\")\n",
    "        return EfficientNet.from_pretrained(model_name.lower(), advprop=False)\n",
    "    elif model_name in pretrainedmodels_models:\n",
    "        print(\"Pulling model from pretrainedmodels model zoo\")\n",
    "        return eval('pretrainedmodels.'+model_name+'()')\n",
    "    elif model_name in timm_models:\n",
    "        print(\"Pulling model from timm model zoo\")\n",
    "        return timm.create_model(model_name, pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(\"No model found under the name {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dict(modelloc_dict):\n",
    "    model_dict = defaultdict(lambda: defaultdict(object))\n",
    "    for _arch, m in modelloc_dict.items():\n",
    "        for _traintype in m.keys():\n",
    "            model = torch.load(modelloc_dict[_arch][_traintype], \n",
    "                                   map_location=torch.device(str(device))) \n",
    "                \n",
    "            #for _p in model.named_children():\n",
    "            #    pass    \n",
    "            \n",
    "            if 'WrappedModel' in str(type(model)):\n",
    "                try:\n",
    "                    print('load model..')\n",
    "                    model = torch.load(modelloc_dict[_arch][_traintype], \n",
    "                                       map_location=torch.device(str(device)))    \n",
    "                    model = WrappedModel(model.module)\n",
    "                    print('load model...')\n",
    "                    _mod = torch.load(modelloc_dict[_arch][_traintype], \n",
    "                                      map_location=torch.device(str(device)))\n",
    "                    _mod.module.eval()\n",
    "                    print('loading weights...')\n",
    "                    state_dict = _mod.module.state_dict()\n",
    "                    #state_dict.pop('_fc.weight')\n",
    "                    #state_dict.pop('_fc.bias')\n",
    "\n",
    "                    if num_gpu>1:\n",
    "                        model= nn.DataParallel(model)        \n",
    "                    model.to(device)\n",
    "\n",
    "                    model.module.load_state_dict(state_dict)\n",
    "                    #num_classes = model.module._fc.out_features\n",
    "                except Exception as e:\n",
    "                    print(\"Failed strategy 1, {}\".format(e))    \n",
    "                    try:            \n",
    "                        model = torch.load(modelloc_dict[_arch][_traintype], \n",
    "                                           map_location=torch.device(str(device)))\n",
    "                        model = WrappedModel(model.module)\n",
    "\n",
    "                        if num_gpu>1:\n",
    "                            model= nn.DataParallel(model) \n",
    "                        model.to(device)           \n",
    "\n",
    "                        model.module.load_state_dict(torch.load(modelloc_dict[_arch][_traintype]),\n",
    "                                                     map_location=torch.device(str(device)))\n",
    "                        #num_classes = model.module._fc.out_features\n",
    "                    except Exception as e:                \n",
    "                        print(\"Problem loading model!, {}\".format(e))\n",
    "                    \n",
    "                model = model.module\n",
    "                        \n",
    "            if use_amp:\n",
    "                print(\"Import model assuming AMP APEX optimisation\")\n",
    "                from apex import amp\n",
    "                checkpoint = torch.load(modelloc_dict[_arch][_traintype])\n",
    "                model = load_base_model(_arch)\n",
    "                model.to(device)\n",
    "                model, _ = amp.initialize(model, None, opt_level='O1')\n",
    "                model.load_state_dict(checkpoint['model'])\n",
    "                amp.load_state_dict(checkpoint['amp'])     \n",
    "\n",
    "            model_dict[_arch][_traintype]= model\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model..\n",
      "load model...\n",
      "loading weights...\n"
     ]
    }
   ],
   "source": [
    "model_dict = create_model_dict(modelloc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader stuffs\n",
    "#\n",
    "def create_loader(**kwargs):\n",
    "    centercrop = kwargs['centercrop']\n",
    "    randomcrop = kwargs['randomcrop']\n",
    "    resize = kwargs['resize']\n",
    "    \n",
    "    img_transforms = [\n",
    "                              transforms.RandomGrayscale(p=0.1),\n",
    "                              Equalize(p=0.2),\n",
    "                              AutoContrast(p=0.4, cutoff=0.2),\n",
    "                              Sharpness(p=0.1, magnitude=3),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.RandomVerticalFlip(),\n",
    "                              transforms.RandomAffine(degrees=60, \n",
    "                                                      translate=(0.05, 0.05),\n",
    "                                                      shear=15,\n",
    "                                                      resample=Image.BILINEAR),\n",
    "                              transforms.ColorJitter(brightness=0.25, contrast=0.15, \n",
    "                                                    saturation=0.15, hue=0.15),                              \n",
    "                              Microscope(p=0.25),\n",
    "                              GaussianBlur(p=0.25, ksize=5),  \n",
    "                              CutOut(p=0.4, min_holes=4, max_holes=24, \n",
    "                                 fill_value=0, max_height=32, max_width=32,\n",
    "                                    min_height=16, min_width=16)\n",
    "                              ]\n",
    "        \n",
    "    transform_list = img_transforms + [\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.RandomErasing(p=0.3, scale=(0.025, 0.05), ratio=(0.05, .1), \n",
    "                                                  value=0, inplace=False),\n",
    "                         transforms.RandomErasing(p=0.2, scale=(0.025, 0.05), ratio=(4, 10), \n",
    "                                                  value=0, inplace=False),\n",
    "                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225],)]\n",
    "    if begin_resize:\n",
    "        opt = [transforms.CenterCrop(centercrop)] if centercrop is not None \\\n",
    "                                                  else [transforms.Resize(randomcrop[0]),\n",
    "                                                        transforms.RandomCrop(randomcrop[1],\n",
    "                                                                              padding=0,\n",
    "                                                                              pad_if_needed=True)] \\\n",
    "                                                    if randomcrop is not None \\\n",
    "                                                        else [resizer]\n",
    "        transform_list = opt + transform_list\n",
    "    else:\n",
    "        opt = [transforms.ToPILImage(), transforms.CenterCrop(centercrop), transforms.ToTensor()] \\\n",
    "                                if centercrop is not None \\\n",
    "                                    else [transforms.ToPILImage(),\n",
    "                                          transforms.Resize(randomcrop[0]),\n",
    "                                          transforms.RandomCrop(randomcrop[1],\n",
    "                                                                padding=0,\n",
    "                                                                pad_if_needed=True),\n",
    "                                          transforms.ToTensor()] \\\n",
    "                                        if randomcrop is not None \\\n",
    "                                        else [Tinterpolate(resize, False)]\n",
    "        transform_list = transform_list + opt\n",
    "\n",
    "\n",
    "    transformer = transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "    dataset = TestDataSet(image_loc,transform=transformer)\n",
    "\n",
    "    return torch.utils.data.DataLoader(dataset, \n",
    "                                              num_workers = 16,\n",
    "                                              shuffle = False,\n",
    "                                              sampler = None,\n",
    "                                              drop_last = False, \n",
    "                                              pin_memory = True if device=='cuda:0' else False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_dict = defaultdict(object)\n",
    "for _arch, _kwargs in run_settings.items():\n",
    "    loader_dict[_arch] = create_loader(**_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_convolve(img, stride, scan_res, model, num_classes, padding=None):\n",
    "        \n",
    "    assert scan_res < np.min(img.shape[2:4]), 'Scan resolution is higher than the smallest image dimension'\n",
    "    \n",
    "    kx = int(np.floor(img.shape[2]/stride))\n",
    "    ky = int(np.floor(img.shape[3]/stride))        \n",
    "    k =  kx * ky\n",
    "    output = np.zeros((k, num_classes))\n",
    "\n",
    "        \n",
    "    w = np.linspace(0, kx-1, kx).astype(int)\n",
    "    h = np.linspace(0, ky-1, ky).astype(int)\n",
    "    \n",
    "    W,H = np.meshgrid(w,h)\n",
    "        \n",
    "    for _k in range(k):\n",
    "        i = _k%kx\n",
    "        j = int(np.floor(_k/kx)) \n",
    "        kxi = W[j,i]\n",
    "        kyj = H[j,i]\n",
    "        win_xl, win_xr  = stride*kxi, stride*kxi+scan_res\n",
    "        win_yd, win_yu  = stride*kyj, stride*kyj+scan_res\n",
    "        \n",
    "        _scan = img[:, :, win_xl:win_xr, win_yd:win_yu]\n",
    "        output[_k,:] = model(_scan.to(device)).to('cpu')\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "# suggestion 1: count ranks, i.e. majority vote\n",
    "cnts = np.zeros((num_classes,))\n",
    "for i in results.shape[0]:    \n",
    "    cnts[np.argmax(results[i,:])] += 1\n",
    "  \n",
    "# suggestion 2: unweighted score summing\n",
    "score_sum = np.zeros((num_classes,))\n",
    "for i in results.shape[0]:    \n",
    "    cnts[:] = cnts[:] + results[i,:]\n",
    "\n",
    "# suggestion 3: unweighted softmax summing\n",
    "score_sum = np.zeros((num_classes,))\n",
    "for i in results.shape[0]:    \n",
    "    cnts[:] = cnts[:] + _softmax(results[i,:])\n",
    "    \n",
    "# add higher weights to higher score entropy, or based on patch location?\n",
    "..\n",
    "..\n",
    "..\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax(x):\n",
    "    # https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "rnd_choice_list = [v for k,v in class_map.items() if k!='mel']\n",
    "def agg_results(x, how='mean_softmax', thres=0.75, mel_ind=None, \n",
    "                weighted=False, inference_weights=None, all_probas=False): \n",
    "    assert isinstance(mel_ind, int), 'Index of melanoma class not given'\n",
    "           \n",
    "    if how=='mean_softmax':\n",
    "        probs = np.zeros((x.shape[1],))\n",
    "        if weighted==False:\n",
    "            for k in range(x.shape[0]):  \n",
    "                probs = probs + _softmax(x[k, :])            \n",
    "        else:\n",
    "            for k in range(x.shape[0]):  \n",
    "                probs = probs + _softmax(x[k, :]*inference_weights) \n",
    "        probs = probs/(k+1)  \n",
    "        if all_probas:\n",
    "            return probs\n",
    "        else:\n",
    "            return probs[mel_ind]\n",
    "    elif how=='softmax_mean_linear':\n",
    "        if weighted==False:\n",
    "            probs = _softmax(np.mean(x, axis=0))\n",
    "        else:\n",
    "            probs = _softmax(np.mean(x, axis=0)*inference_weights)\n",
    "            \n",
    "        if all_probas:\n",
    "            return probs\n",
    "        else:\n",
    "            return probs[mel_ind]\n",
    "    elif how=='logmean':\n",
    "        probs = np.zeros((x.shape[1],))\n",
    "        if weighted==False:\n",
    "            for k in range(x.shape[0]):  \n",
    "                probs = probs + np.log(_softmax(x[k, :]))          \n",
    "        else:\n",
    "            for k in range(x.shape[0]):  \n",
    "                probs = probs + _softmax(x[k, :]*inference_weights) \n",
    "        probs = np.exp(probs/(k+1))  \n",
    "        if all_probas:\n",
    "            return probs\n",
    "        else:\n",
    "            return probs[mel_ind]\n",
    "\n",
    "def smart_mean(x):    \n",
    "    xw = np.abs(x.values - 0.5)     \n",
    "    wm = np.dot(x.values.T, xw)\n",
    "    if x.shape[1]>1:        \n",
    "        return pd.Series(np.diag(wm), index=x.columns)/np.sum(xw)\n",
    "    else:\n",
    "        return wm[0][0]/sum(np.sum(xw))\n",
    "    \n",
    "def log_mean(x):\n",
    "    # only for aggregation (i.e. columnwise)\n",
    "    return np.exp(np.mean(np.log(x)))\n",
    "    \n",
    "    \n",
    "def model_run(model, num_classes, data_loader, _archname, traintype, smart_mean, get_all_probas, **kwargs):   \n",
    "    stride = kwargs['stride']\n",
    "    scan_res = kwargs['scan_res']\n",
    "    TTA = kwargs['TTA']\n",
    "    proba_aggregation = kwargs['proba_aggregation']\n",
    "    use_inference_weights = kwargs['use_inference_weights']\n",
    "    \n",
    "    res_list = []\n",
    "    model.eval()\n",
    "    #class_count = defaultdict(int)\n",
    "    proba_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for _m in range(TTA):\n",
    "            print(\"Starting on TTA round {}\".format(_m))\n",
    "            for idx, data in tqdm(enumerate(data_loader, 0)):\n",
    "                \n",
    "                # \n",
    "                # get image size tuple\n",
    "                im_size = data[0].shape\n",
    "                im_loc = data[1]    \n",
    "                im_name = im_loc[0].split(\"/\")[-1].strip(\"\\.jpg\")\n",
    "                try:\n",
    "                    results = model_convolve(data[0], stride, scan_res, model, num_classes, padding=None)\n",
    "                except Exception as e:\n",
    "                    print(\"Convolving inference failed: {}. On image: {}\".format(e, im_name))\n",
    "                    \n",
    "                res = agg_results(results, how=proba_aggregation, \n",
    "                                  mel_ind=class_map['mel'], inference_weights=ind_weights,\n",
    "                                  weighted=use_inference_weights, all_probas=get_all_probas)      \n",
    "\n",
    "                if get_all_probas:\n",
    "                    tdict = {ind_class[idx]:_p for idx, _p in enumerate(res)}\n",
    "                    tdict['image_name'] = im_name\n",
    "                    tdict['tta_run'] = _m\n",
    "                    res_list.append(tdict)                                        \n",
    "                else:\n",
    "                    res_list.append({'image_name': im_name,\n",
    "                                     'target': res,\n",
    "                                     'tta_run': _m})\n",
    "                proba_sum += res\n",
    "                if (idx % 50 == 49) & (debug==True):\n",
    "                    break                \n",
    "                if idx % 2500 == 0:\n",
    "                    print(\"Mean melanoma probability is: {}\".format(100*proba_sum/(idx+1+_m*test_count)))\n",
    "                    \n",
    "                \n",
    "            res_df = pd.DataFrame(res_list)\n",
    "\n",
    "            #fileString = \"PREDICTIONS/\"+image_loc.split(\"/\")[0]+\"_\"+_archname+\"_\"+traintype+\"_TTA\"+str(_m)+\"_smartmean.csv\"\n",
    "            #res_df_sm = res_df.groupby('image_name').apply(smart_mean).reset_index()\n",
    "            #if get_all_probas==False:\n",
    "            #    res_df_sm[['image_name', 'target']].to_csv(fileString, sep=\",\", index=False)\n",
    "            #res_df_sm['arch'] = _archname+\"_\"+traintype+\"_TTA\"+str(_m)\n",
    "\n",
    "            fileString = \"PREDICTIONS/\"+image_loc.split(\"/\")[0]+\"_\"+_archname+\"_\"+traintype+\"_TTA\"+str(_m)+\"_normmean.csv\"\n",
    "            res_df_norm = res_df.groupby('image_name').mean().reset_index()\n",
    "            if get_all_probas==False:\n",
    "                res_df_norm[['image_name', 'target']].to_csv(fileString, sep=\",\", index=False)\n",
    "            res_df_norm['arch'] = _archname+\"_\"+traintype+\"_TTA\"+str(_m)    \n",
    "\n",
    "    if smart_mean:\n",
    "        return res_df_sm\n",
    "    else:\n",
    "        return res_df_norm        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: efficient_net_b0, traintype: resize\n",
      "Starting on TTA round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.856242911556992e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2505it [00:54, 45.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.120822789947058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5008it [01:47, 43.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.332921707615363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7510it [02:39, 48.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.16391138130003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10010it [03:32, 46.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.170760453275706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:53, 47.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.185584270999806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2505it [00:53, 49.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.185112719117683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5005it [01:46, 45.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.1739723374001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7510it [02:39, 45.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.096594332056153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10006it [03:32, 45.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.085085999110804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:53, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.08108951363426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2511it [00:53, 49.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.078929987691522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5006it [01:46, 47.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.132770503272027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7505it [02:39, 44.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.08971650824337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10007it [03:32, 45.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.133244211928577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:52, 47.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.118903545762253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2506it [00:53, 46.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.120672653968564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [01:46, 43.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.15098083075978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7506it [02:39, 44.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.135763995539241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10009it [03:32, 46.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.138740478073705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:53, 47.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.12322884392314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2509it [00:54, 48.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.143689566394304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [01:46, 46.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.164154454030834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7508it [02:39, 45.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.155958299452138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10006it [03:33, 45.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.164570607521487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:53, 47.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.175806614522273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2507it [00:53, 47.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.179868805882236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5006it [01:46, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.179959512906784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7509it [02:39, 45.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.169173050226537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10009it [03:32, 45.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.154902957904397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:52, 47.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.161287050560867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2508it [00:53, 47.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.176446258532538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [01:46, 46.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.191389477362835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7507it [02:39, 45.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.167757999601898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10009it [03:33, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 9.173158584891844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [03:53, 47.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: regnet_064, traintype: resize\n",
      "Starting on TTA round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 0.02587336026214255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2506it [01:08, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.276872406838363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5005it [02:16, 37.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.293760510016655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7504it [03:23, 36.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.116651561905545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10007it [04:31, 35.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.069944856971507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:57, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.085896725785458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2507it [01:08, 37.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.092514396525997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5008it [02:16, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.131652605889593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7506it [03:24, 37.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.064943603851468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10008it [04:31, 34.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.071639500918302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:58, 36.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.099461079336882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2506it [01:08, 38.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.079021041282477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5004it [02:16, 36.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.082975596464227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7505it [03:24, 34.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.039726531789245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10007it [04:32, 37.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.027674675790475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:58, 36.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.046550693277705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2508it [01:08, 37.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.025807345808254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [02:16, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.040995731215219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7506it [03:24, 36.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.04107889108446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10005it [04:32, 37.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.036981393542696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:58, 36.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.052471508893616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2508it [01:08, 37.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.049803000039516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [02:16, 37.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.060683880445621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7506it [03:24, 37.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.044515682468221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10005it [04:32, 37.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.036464981701924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:59, 36.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.04845113375143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2507it [01:08, 38.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.047036690353362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5008it [02:16, 35.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.050891887818638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7507it [03:23, 36.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.040173012840723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10008it [04:31, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.032276323131933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:58, 36.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.03888119183775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2507it [01:08, 33.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.035373500581407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5006it [02:16, 32.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.037723440559859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7506it [03:24, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.038168394904892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10005it [04:32, 36.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 8.042975126313939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [04:59, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: regnet_064, traintype: centercrop\n",
      "Starting on TTA round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 1.2162251031928049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2502it [03:42, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.271253047686172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [07:21, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3540365338356164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7503it [11:07, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.296817852471426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10003it [14:59, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3069374169086125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:31, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3084755668808215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2502it [03:54, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3163114494234294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [07:45, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3269484194670156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [11:36, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.2901141271549608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10003it [15:24, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3101019638488265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:54, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.308221882253626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [03:44, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3181102853064735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [07:36, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.328741403932561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7503it [11:28, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.319034971304157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10003it [15:17, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3203381829849556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:44, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.322226324032766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2502it [03:43, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3273839116082025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5003it [07:25, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3335130978266694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [11:07, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.330889940540361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10002it [14:55, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.330232644913129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:25, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3341358131970136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2503it [03:49, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.343403534605884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5003it [07:39, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.352068079257254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [11:28, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3463686503699988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10003it [15:17, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3422524244466936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:48, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3445393801664856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2502it [03:52, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3485135746663137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [07:44, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3516259561042037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [11:31, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.34404802507075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10002it [15:10, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3405691292681423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:36, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on TTA round 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3409748146040354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2503it [03:40, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.341910319379344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5003it [07:18, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3468633899003395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [10:57, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.3445957832231996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10002it [14:37, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean melanoma probability is: 3.339804554924582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [16:03, 11.40it/s]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for _archname in model_dict.keys():       \n",
    "    for _traintype, _model in model_dict[_archname].items(): \n",
    "        print(\"architecture: {}, traintype: {}\".format(_archname, _traintype))\n",
    "        _kwargs = run_settings[_traintype]\n",
    "        _res = model_run(_model, \n",
    "                         num_classes,\n",
    "                         loader_dict[_traintype], \n",
    "                         _archname, \n",
    "                         _traintype, \n",
    "                         smart_mean,\n",
    "                         get_all_probas,\n",
    "                         **_kwargs)\n",
    "        tot_res = pd.concat([tot_res, _res]) if cnt>0 else _res\n",
    "        cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "* create multiple test images using augmentations: augment+scan+multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcols = list(set(tot_res.columns)-set(['tta_run', 'arch', 'image_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = tot_res[tcols+['image_name']].groupby('image_name').apply(smart_mean).reset_index()\n",
    "tunw = tot_res[tcols+['image_name']].groupby('image_name').mean().reset_index()\n",
    "tlog2 = tot_res[tcols+['image_name']].groupby('image_name').apply(log_mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw.columns = ['image_name', 'target']\n",
    "tunw.columns = ['image_name', 'target']\n",
    "tlog2.columns = ['image_name', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_all_probas:\n",
    "    threshold=0.9\n",
    "    def get_max(x):    \n",
    "        _amax = np.argmax(x)\n",
    "        if x[_amax]>threshold:\n",
    "            return x.index[_amax]\n",
    "        else:\n",
    "            return np.nan\n",
    "    tw['target'] = tw[tcols].apply(get_max, axis=1)\n",
    "    tunw['target'] = tunw[tcols].apply(get_max, axis=1)\n",
    "    tlog2['target'] = tlog2[tcols].apply(get_max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw.to_csv('weighted_total.csv', sep=',', index=False)\n",
    "tunw.to_csv('unweighted_total.csv', sep=',', index=False)\n",
    "tlog2.to_csv('log2weighted_total.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if submit_to_kaggle:    \n",
    "    #!kaggle competitions submit -c siim-isic-melanoma-classification -f /home/bramiozo/DATA/ISIC2020/weighted_total.csv -m \"Weighted total\"\n",
    "    #!kaggle competitions submit -c siim-isic-melanoma-classification -f /home/bramiozo/DATA/ISIC2020/unweighted_total.csv -m \"Unweighted total\"\n",
    "    #!kaggle competitions submit -c siim-isic-melanoma-classification -f /home/bramiozo/DATA/ISIC2020/unweighted_total.csv -m \"Log2 weighted total\"\n",
    "    !kaggle competitions submit -c siim-isic-melanoma-classification -f /media/bramiozo/DATA-FAST/kaggle/image_classification/MEDICAL/melanoma/weighted_total.csv -m \"Weighted total\"\n",
    "    !kaggle competitions submit -c siim-isic-melanoma-classification -f /media/bramiozo/DATA-FAST/kaggle/image_classification/MEDICAL/melanoma/unweighted_total.csv -m \"Unweighted total\"\n",
    "    !kaggle competitions submit -c siim-isic-melanoma-classification -f /media/bramiozo/DATA-FAST/kaggle/image_classification/MEDICAL/melanoma/unweighted_total.csv -m \"Log2 weighted total\"\n",
    "    !poweroff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_image",
   "language": "python",
   "name": "torch_image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
